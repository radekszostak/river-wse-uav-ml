{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674183f-00eb-4a57-a7e2-d684fae33f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96c3ef-9c5b-47d4-a581-0dec7fa7a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from swa import SWA\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import WseDataset\n",
    "from utils import train, predict, printc\n",
    "from models.vgg import Vgg\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.outliers_influence import summary_table\n",
    "except ModuleNotFoundError:\n",
    "    !pip install statsmodels -q\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.outliers_influence import summary_table\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "try:\n",
    "    import neptune.new as neptune\n",
    "except ModuleNotFoundError:\n",
    "    !pip install neptune-client -q\n",
    "    import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d3d47-e73b-4ac7-8004-ca51e7fed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"img_size\": 256,\n",
    "    \"model\": \"vgg\",#\"vgg\"\n",
    "    \"lr_base\": 0.000001,#0.00001,\n",
    "    \"lr_max\": 0.00001,#0.00001,\n",
    "    \"swa_start\": 6,\n",
    "    \"swa_freq\": 2,\n",
    "    \"swa_lr\": 0.000002,\n",
    "    \"batch_size\": 32,\n",
    "    'epochs': 50,\n",
    "    'task': \"all\",#\"all\", \"train\", \"predict\"\n",
    "    'neptune': False,\n",
    "    'es_patience': 10,#10,#15, # early stopping (es), negative - early stopping disabled\n",
    "    'es_min_delta': 0.001, # early stopping (es)\n",
    "    'drop_rate': 0.5, # dropout rate\n",
    "    'train_subsets': [\"GRO20\", \"RYB20\", \"RYB21\"],\n",
    "    'valid_subsets': [\"GRO21\"],\n",
    "    'test_subsets': None,\n",
    "    'dropout_averaging': True,\n",
    "    'overtrain': False,\n",
    "    'min_range': 0.,#4.,\n",
    "    'max_range': 4.5,#float('inf'),\n",
    "    'pretrained_weights': None,#\"output/DEN1-1067/state_dict.pth\",#None,#None,# None,\"state_dict.pth\",\n",
    "    'optimizer': \"adam\"#\"adam\"/\"swa\"/\"sgd\"\n",
    "}\n",
    "\n",
    "dataset_dir = os.path.normpath(\"dataset\")\n",
    "csv_path = os.path.join(dataset_dir,\"dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb75b8-f229-48b5-b326-7a6558eabd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_ipython().__class__.__name__ != 'ZMQInteractiveShell':\n",
    "    if len(sys.argv)>1:\n",
    "        PARAMS['train_subsets']=None if sys.argv[1]==\"None\" else sys.argv[1].split(\",\")\n",
    "        PARAMS['valid_subsets']=None if sys.argv[2]==\"None\" else sys.argv[2].split(\",\")\n",
    "        PARAMS['test_subsets']=None if sys.argv[3]==\"None\" else sys.argv[3].split(\",\")\n",
    "print(PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec713fa2-f6af-4489-9c7a-0c5fb2ec60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"output\", exist_ok=True)\n",
    "if PARAMS[\"neptune\"]:\n",
    "    import configparser\n",
    "    config = configparser.ConfigParser()\n",
    "    assert os.path.exists(\"ml/config.cfg\")\n",
    "    config.read(\"ml/config.cfg\")\n",
    "\n",
    "    neptune_run = neptune.init(project=config[\"neptune\"][\"project\"],\n",
    "              api_token=config[\"neptune\"][\"token\"],\n",
    "              source_files=['ml/main.py', f\"ml/models/{PARAMS['model']}.py\", 'ml/utils.py', 'ml/dataloader.py']\n",
    "              )\n",
    "    neptune_run[\"parameters\"] = PARAMS\n",
    "    output_name = neptune_run.get_structure()['sys']['id'].fetch()\n",
    "    output_dir = f\"output/{output_name}\"\n",
    "    os.mkdir(output_dir)\n",
    "else:\n",
    "    neptune_run=None\n",
    "    output_dir = f\"output/{PARAMS['valid_subsets'][0]}\"\n",
    "    if os.path.exists(output_dir) and os.path.isdir(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.mkdir(output_dir)\n",
    "# device detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {device}\")\n",
    "if str(device) == \"cuda\":\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "      print(f\"\\tcuda:{i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# model loading\n",
    "if PARAMS[\"model\"]==\"vgg\":\n",
    "    model = Vgg(input_size=PARAMS[\"img_size\"], drop_rate=PARAMS[\"drop_rate\"]).to(device)\n",
    "    printc(model, \"Model:\")\n",
    "if PARAMS[\"pretrained_weights\"]:\n",
    "    model.load_state_dict(torch.load(PARAMS[\"pretrained_weights\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d412f31-cf97-4f23-a85d-c47e7f8e13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARAMS[\"train_subsets\"]:\n",
    "    train_dataset = WseDataset(csv_path=csv_path, img_size=PARAMS['img_size'], augment=True, subsets=PARAMS[\"train_subsets\"], min_range = PARAMS[\"min_range\"], max_range = PARAMS[\"max_range\"])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "else:\n",
    "    train_dataloader = None\n",
    "if PARAMS[\"valid_subsets\"]:    \n",
    "    valid_dataset = WseDataset(csv_path=csv_path, img_size=PARAMS['img_size'], augment=False, subsets=PARAMS[\"valid_subsets\"], min_range = PARAMS[\"min_range\"], max_range = PARAMS[\"max_range\"])\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "else:\n",
    "    valid_dataloader = None\n",
    "if PARAMS[\"test_subsets\"]:    \n",
    "    test_dataset = WseDataset(csv_path=csv_path, img_size=PARAMS['img_size'], augment=False, subsets=PARAMS[\"test_subsets\"], min_range = PARAMS[\"min_range\"], max_range = PARAMS[\"max_range\"])\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "else:\n",
    "    test_dataloader = None\n",
    "    \n",
    "if PARAMS[\"optimizer\"] == \"adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=PARAMS[\"lr_base\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=PARAMS[\"lr_base\"], max_lr=PARAMS[\"lr_max\"],step_size_up=2,mode=\"triangular\",cycle_momentum=False)\n",
    "elif PARAMS[\"optimizer\"] == \"sgd\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=PARAMS[\"learning_rate\"])\n",
    "elif PARAMS[\"optimizer\"] == \"swa\":\n",
    "    #base_optimizer = torch.optim.SGD(model.parameters(), lr=PARAMS[\"learning_rate\"])\n",
    "    base_optimizer = torch.optim.Adam(model.parameters(), lr=PARAMS[\"lr_base\"])\n",
    "    optimizer = SWA(base_optimizer, swa_start=PARAMS[\"swa_start\"], swa_freq=PARAMS[\"swa_freq\"], swa_lr=PARAMS[\"lr_max\"])\n",
    "\n",
    "model = train(model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            valid_dataloader=valid_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            num_epochs=PARAMS['epochs'],\n",
    "            es_patience=PARAMS['es_patience'],\n",
    "            es_min_delta=PARAMS['es_min_delta'],\n",
    "            dropout_averaging=PARAMS[\"dropout_averaging\"],\n",
    "            output_dir=output_dir,\n",
    "            neptune_run=neptune_run\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933d218-7361-495c-968a-de8cd1cfa8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARAMS[\"train_subsets\"]:\n",
    "    train_dataset = WseDataset(csv_path=csv_path, img_size=PARAMS['img_size'], augment=False, subsets=PARAMS[\"train_subsets\"], min_range = PARAMS[\"min_range\"], max_range = PARAMS[\"max_range\"])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "else:\n",
    "    train_dataloader = None\n",
    "if PARAMS[\"valid_subsets\"]:\n",
    "    valid_dataset = WseDataset(csv_path=csv_path, img_size=PARAMS['img_size'], augment=False, subsets=PARAMS[\"valid_subsets\"], min_range = PARAMS[\"min_range\"], max_range = PARAMS[\"max_range\"])\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "else:\n",
    "    valid_dataloader = None\n",
    "if train_dataloader:\n",
    "    predict(model, dataloader=train_dataloader, averaging=PARAMS['dropout_averaging'], device=device, output_name=\"train\", dropout_averaging=PARAMS[\"dropout_averaging\"], output_dir=output_dir, neptune_run=neptune_run)\n",
    "if valid_dataloader:\n",
    "    predict(model, dataloader=valid_dataloader, averaging=PARAMS['dropout_averaging'], device=device, output_name=\"valid\", dropout_averaging=PARAMS[\"dropout_averaging\"], output_dir=output_dir, neptune_run=neptune_run)\n",
    "    result_dict_path = f\"{output_dir}/predictions/valid.pickle\"\n",
    "    if PARAMS[\"neptune\"]:\n",
    "        neptune_run[f\"predict/test/result_dict\"].upload(result_dict_path)\n",
    "    with open(result_dict_path, 'rb') as f:\n",
    "        result_dict = pickle.load(f)\n",
    "        gt_y = result_dict[\"info\"][\"wse\"].to_numpy()\n",
    "        mean_y = result_dict[\"predict\"].mean(axis=0).to_numpy()\n",
    "        std_y = result_dict[\"predict\"].std(axis=0).to_numpy()\n",
    "        fit_x = result_dict[\"info\"][\"chain\"].to_numpy()\n",
    "        gt_reg = sm.OLS(gt_y, sm.add_constant(fit_x)).fit()\n",
    "        pr_reg = sm.OLS(mean_y, sm.add_constant(fit_x)).fit()\n",
    "        pr_st, pr_data, pr_ss2 = summary_table(pr_reg, alpha=0.05)\n",
    "        gt_st, gt_data, gt_ss2 = summary_table(gt_reg, alpha=0.05)\n",
    "        pred_y = pr_data[:,2]\n",
    "        gt_pred_y = gt_data[:,2]\n",
    "        #predict_ci_low, predict_ci_upp = pr_data[:,6:8].T\n",
    "        b, a = pr_reg.params\n",
    "        b_std, a_std = pr_reg.bse\n",
    "        predict_low = (a-a_std)*fit_x + (b-b_std)\n",
    "        predict_upp = (a+a_std)*fit_x + (b+b_std)\n",
    "        errors = predict_upp - pred_y\n",
    "        regression_rmse = np.sqrt(((pred_y-result_dict[\"info\"][\"wse\"])**2).mean())\n",
    "        mean_error = (pred_y-predict_low).mean()\n",
    "        print(f\"Test regression RMSE: {regression_rmse}\")\n",
    "        if PARAMS[\"neptune\"]:\n",
    "            neptune_run[f\"predict/test/regression_RMSE\"] = regression_rmse\n",
    "        print(f\"Test mean error: {mean_error}\")\n",
    "        if PARAMS[\"neptune\"]:\n",
    "            neptune_run[f\"predict/test/regression_error\"] = mean_error\n",
    "        slopes = {\"slope_mm_gt\": (gt_pred_y[-1]-gt_pred_y[0])/(fit_x[-1]-fit_x[0]),\n",
    "                  \"slope_deg_gt\": math.degrees(math.atan(gt_reg.params[1])),\n",
    "                  \"slope_mm_pr\": (pred_y[-1]-pred_y[0])/(fit_x[-1]-fit_x[0]),\n",
    "                  \"slope_deg_pr\": math.degrees(math.atan(pr_reg.params[1]))}\n",
    "        if PARAMS[\"neptune\"]:\n",
    "            neptune_run[f\"predict/test/slopes\"] = slopes\n",
    "            neptune_run[f\"predict/test/slope_diff_deg\"] = slopes[\"slope_deg_gt\"]-slopes[\"slope_deg_pr\"]\n",
    "        plt.plot(result_dict[\"info\"][\"chain\"],gt_pred_y, \"-\", label=\"Ground truth linear\", color=\"yellow\")\n",
    "        plt.plot(result_dict[\"info\"][\"chain\"],result_dict[\"info\"][\"wse\"], \"-\", label=\"Ground truth\", color=\"green\")\n",
    "        plt.plot(result_dict[\"info\"][\"chain\"],result_dict[\"predict\"].mean(axis=0), \"x\", label=\"CNN output\", color=\"blue\")\n",
    "        plt.plot(result_dict[\"info\"][\"chain\"],pred_y, \"-\", label=\"CNN output regression\", color=\"blue\")\n",
    "        plt.plot(result_dict[\"info\"][\"chain\"],predict_low, \"--\", label=\"Error Up\", color=\"blue\")\n",
    "        plt.plot(result_dict[\"info\"][\"chain\"],predict_upp, \"--\", label=\"Error Down\", color=\"blue\")\n",
    "        if PARAMS[\"neptune\"]:\n",
    "            neptune_run[f\"predict/test/figure\"].upload(neptune.types.File.as_image(plt.gcf()))\n",
    "if PARAMS[\"neptune\"]:\n",
    "    neptune_run.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
